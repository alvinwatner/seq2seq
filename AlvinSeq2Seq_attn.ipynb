{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AlvinSeq2Seq_attn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4k9XjgozwgN"
      },
      "source": [
        "#<div align=\"center\">Sequence to Sequence + Attention</div>\n",
        "\n",
        "---\n",
        "###### Author     : alvinwatner\n",
        "###### Inspired by : Aladdin Persson (https://www.youtube.com/watch?v=EoGUlvhRYpk&t=2146s)\n",
        "---\n",
        "\n",
        "##To reproduce : \n",
        "\n",
        "1.   Make sure you have utils.py inside your google drive, otherwise there are 2 ways to acquire utils.py file :\n",
        "\n",
        "  *   Open and Run the [utils.ipynb](https://colab.research.google.com/drive/1tkh9NyoKLfl4gk8L3_JKVGfCMIXDLy37?usp=sharing).\n",
        "  *   Download from this [link](https://drive.google.com/file/d/18RMp42VvfMSdUfxxYKR_1QiA5fWcbgus/view?usp=sharing).\n",
        "\n",
        "  Also make sure the **utils.py** is inside the **main_path** directory that specified on the *second cell*.\n",
        "\n",
        "\n",
        "2. Create \"**Checkpoint**\" folder inside the **main_path**.\n",
        "3. Create \"**plot**\" folder inside the **main_path** .\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<br/>\n",
        "\n",
        "---\n",
        "\n",
        "###### *Note : Don't forget to change runtime type to **GPU**, and **CTRL + F9** to run all cells, otherwise the training will run super slow. Enjoy~*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCTxKL2kWNmE",
        "outputId": "590a6f8d-96dc-4894-ebdb-2c081a2ab572"
      },
      "source": [
        "# Mount to gdrive and have a peek to current path\n",
        "from google.colab import drive \n",
        "drive. mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6x0_fBw2WPhR"
      },
      "source": [
        "# Main path for tensorboard and checkpoint\n",
        "main_path = '/content/drive/MyDrive/Colab Notebooks/NLP/Pytorch/Seq2seq/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2Wv9VFBWTNw",
        "outputId": "5661f205-4deb-4056-bc46-b43ccc70e03f"
      },
      "source": [
        "# Path to utils.py root folder\n",
        "%cd /content/drive/MyDrive/Colab Notebooks/NLP/Pytorch/Seq2seq"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/NLP/Pytorch/Seq2seq\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaCMVD02WZRb",
        "outputId": "4c6a2125-e606-4adf-ab2b-a7493987e796"
      },
      "source": [
        "!ls -l utils.py"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw------- 1 root root 2415 Dec 23 03:36 utils.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34EytGVdWzF5"
      },
      "source": [
        "#import utils.py as module\n",
        "from utils import translate_sentence, bleu, save_checkpoint, load_checkpoint"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVfApfxNEjsc"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch.optim as optim\n",
        "from torchtext.datasets import Multi30k\n",
        "from torchtext.data import Field, BucketIterator\n",
        "\n",
        "import numpy as np \n",
        "import random\n",
        "import spacy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaOic_OWX65X",
        "outputId": "4faaf596-4713-4e4d-dc44-450dc4b3ba03"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"device = {device}\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device = cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5dP5LYI4GS6"
      },
      "source": [
        "!pip install torchtext==0.6.0 \n",
        "!python -m spacy download de #Language degerman\n",
        "!python -m spacy download en #Language enlish"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlkWlfJ_33tf"
      },
      "source": [
        "spacy_ger = spacy.load('de')\n",
        "spacy_en = spacy.load('en')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3hL2RbM4WeF"
      },
      "source": [
        "def tokenizer_ger(text):\n",
        "  return [tok.text for tok in spacy_ger.tokenizer(text)]\n",
        "\n",
        "def tokenizer_en(text):\n",
        "  return [tok.text for tok in spacy_en.tokenizer(text)]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcGcAcJ553wZ"
      },
      "source": [
        "gerField = Field(tokenize = tokenizer_ger, lower = True,\\\n",
        "                    init_token = '<SOS>', eos_token = '<EOS>')\n",
        "enField = Field(tokenize = tokenizer_en, lower = True,\\\n",
        "                init_token = '<SOS>', eos_token = '<EOS>')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGDSNNGI5c7m"
      },
      "source": [
        "train_data, valid_data, test_data = Multi30k.splits(exts=('.de', '.en'), fields = (gerField, enField))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlvgZKmpUbjI"
      },
      "source": [
        "gerField.build_vocab(train_data, max_size = 10000, min_freq = 2)\n",
        "enField.build_vocab(train_data, max_size = 10000, min_freq = 2)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wa3G0aDL8dLi"
      },
      "source": [
        "encoder_input_size = len(gerField.vocab)\n",
        "decoder_input_size = len(enField.vocab)\n",
        "num_layers = 2\n",
        "hidden_size = 1024\n",
        "batch_size = 32\n",
        "embedding_dim = 300\n",
        "dropout = 0.5\n",
        "num_epochs = 10"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoH4n6Lh6_DX"
      },
      "source": [
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size = batch_size,\n",
        "    sort_within_batch = True,\n",
        "    sort_key = lambda x : len(x.src),\n",
        "    device = device\n",
        ")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScKcE1PeKu2H"
      },
      "source": [
        "# Encoder version 1.5\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, input_size, embedding_dim, hidden_size, num_layers, dropout, isBidirectional = True):\n",
        "    super().__init__()\n",
        "    self.num_direction = 2 if isBidirectional else 1\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.embedding = nn.Embedding(input_size, embedding_dim)\n",
        "    self.rnn = nn.LSTM(embedding_dim, hidden_size, num_layers,\n",
        "                       bidirectional = True, dropout = dropout)\n",
        "    self.fc_hc = nn.Linear(hidden_size * self.num_direction, hidden_size)\n",
        "    self.fc_out = nn.Linear(hidden_size * self.num_direction, hidden_size)\n",
        "\n",
        "  def forward(self, inp):    \n",
        "    #inp.shape = (seq_length, batch_size)\n",
        "\n",
        "    embedded = self.dropout(self.embedding(inp))\n",
        "    #embedded.shape = (seq_length, batch_size, embedding_dim)\n",
        "\n",
        "    hj, (hidden, cell) = self.rnn(embedded)\n",
        "    #hj           = (seq_length, batch_size, hidden_size * num_direction)\n",
        "    #hidden.shape = (num_layer * num_direction, batch_size, hidden_size)\n",
        "    #cell.shape   = (num_layer * num_direction, batch_size, hidden_size)\n",
        "\n",
        "    batch_size  = hidden.shape[1]\n",
        "    hidden_size = hidden.shape[2]\n",
        "\n",
        "    hj = self.fc_out(hj)\n",
        "    #h.shape = (seq_length, batch_size, hidden_size)\n",
        "\n",
        "    hidden = hidden.view(self.num_layers, batch_size, hidden_size * self.num_direction)\n",
        "    #hidden.shape = (num_layers, batch_size, hidden_size * num_direction)\n",
        "    cell = cell.view(self.num_layers, batch_size, hidden_size * self.num_direction)\n",
        "    # cell.shape = (num_layers, batch_size, hidden_size * num_direction)\n",
        "\n",
        "    hidden = self.fc_hc(hidden)\n",
        "    cell   = self.fc_hc(cell)\n",
        "    #hidden.shape = (num_layers, batch_size, hidden_size)\n",
        "    #cell.shape = (num_layers, batch_size, hidden_size)\n",
        "\n",
        "    return hj, hidden, cell"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_tCIVrxm2nQ"
      },
      "source": [
        "# Decoder version 1.5\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, input_size, embedding_dim, hidden_size, num_layers, dropout):\n",
        "    super().__init__()\n",
        "    vocab_size      = input_size\n",
        "    self.num_layers = num_layers\n",
        "    self.dropout    = nn.Dropout(dropout)\n",
        "    self.rnn        = nn.LSTM(embedding_dim, hidden_size, num_layers, dropout = dropout)\n",
        "    self.embedding  = nn.Embedding(input_size, embedding_dim)\n",
        "    self.fc_decoder = nn.Linear(hidden_size, vocab_size)\n",
        "    self.fc_energy  = nn.Linear(hidden_size * num_layers, 1)\n",
        "    self.fc_si      = nn.Linear(hidden_size * num_layers, hidden_size)\n",
        "    self.softmax    = nn.Softmax(dim = 0)\n",
        "\n",
        "  '''hj are the encoder output'''\n",
        "  '''s_i_minOne is the decoder hidden_state at time step i_minONE'''\n",
        "  def alignment(self, s_i_minOne, hj):\n",
        "    #hj.shape         = (seq_length, batch_size, hidden_size)\n",
        "    #s_i_minOne.shape = (num_layers, batch_size, hidden_size)\n",
        "    \n",
        "    seq_length  = hj.shape[0] \n",
        "    \n",
        "    num_layers  = s_i_minOne.shape[0]\n",
        "    batch_size  = s_i_minOne.shape[1]\n",
        "    hidden_size = s_i_minOne.shape[2]\n",
        "    \n",
        "    s_i_minOne = s_i_minOne.view(1, batch_size, hidden_size * num_layers)\n",
        "    #s_i_minOne.shape = (1, batch_size, hidden_size * num_layers)\n",
        "    s_i_minOne = self.fc_si(s_i_minOne)\n",
        "    #s_i_minOne.shape = (1, batch_size, hidden_size)\n",
        "    \n",
        "    s_i_minOne = s_i_minOne.repeat(seq_length, 1, 1)\n",
        "    #s_i_minOne.shape = (seq_length, batch_size, hidden_size)\n",
        "\n",
        "    energy = torch.cat((s_i_minOne, hj), dim = 2)\n",
        "    #energy.shape = (seq_length, batch_size, hidden_size * 2)\n",
        "    energy = self.fc_energy(energy)\n",
        "    #energy.shape = (seq_length, batch_size, 1)\n",
        "    return energy\n",
        "  \n",
        "  def context_ops(self, energy, h_j):\n",
        "    '''c = ∑ α.h'''\n",
        "    α = self.softmax(energy)\n",
        "    # α.shape = (seq_length, batch_size, 1)\n",
        "    # h_j     = (seq_length, batch_size, hidden_size) \n",
        "\n",
        "    seq_length  = α.shape[0]\n",
        "    batch_size  = α.shape[1]\n",
        "    hidden_size = h_j.shape[2]\n",
        "\n",
        "    context_vector = torch.empty(seq_length, batch_size, hidden_size).to(device)\n",
        "\n",
        "    ''' c = ∑ α.h Linear combination between α_ij * h_j where, α_ij = scalar and h_j = vector with size = 'hidden_size'  '''\n",
        "    for j in range(seq_length):\n",
        "      for batch_idx in range(batch_size):\n",
        "        context_vector[j, batch_idx] = α[j, batch_idx] * h_j[j, batch_idx]\n",
        "\n",
        "    '''\n",
        "    = iteration sample =\n",
        "    /word-1 ; sentence-1/ probability = 0.7  *  /word-1 ; sentence-1/ hidden_size = h1_1 |  \n",
        "    /word-1 ; sentence-2/ probability = 0.2  *  /word-1 ; sentence-2/ hidden_size = h1_2 | => Where h_ij = vector with size 'hidden_size'    \n",
        "    /word-1 ; sentence-3/ probability = 0.1  *  /word-1 ; sentence-3/ hidden_size = h1_3 |   \n",
        "    '''    \n",
        "\n",
        "    context_vector = torch.sum(context_vector, dim = 0)\n",
        "    #context_vector.shape = (batch_size, hidden_size)\n",
        "    context_vector = context_vector.unsqueeze(0)\n",
        "    #context_vector.shape = (1, batch_size, hidden_size)\n",
        "    context_vector = context_vector.repeat(2, 1, 1)\n",
        "    #context_vector.shape = (2, batch_size, hidden_size) \n",
        "    \n",
        "    return context_vector\n",
        "  \n",
        "  # si_negOne.shape = (2, 32, 1024)\n",
        "  # cell.shape      = (2, 32, 1024)\n",
        "  def forward(self, hj, s_i_minOne, cell, inp):\n",
        "    #inp.shape = (batch_size,)\n",
        "    inp = inp.unsqueeze(0)\n",
        "    #inp.shape = (1, batch_size)\n",
        "    embedded = self.dropout(self.embedding(inp))\n",
        "    #embedding.shape =  (1, batch_size, embedding_dim)\n",
        "    energy = self.alignment(s_i_minOne, hj)\n",
        "    #energy.shape = (seq_length, batch_size, 1)\n",
        "    \n",
        "    context_vector = self.context_ops(energy, hj)\n",
        "    #context_vector.shape = (2, batch_size, hidden_size)\n",
        "\n",
        "    de_out, (hidden, cell) = self.rnn(embedded, (context_vector, cell))\n",
        "\n",
        "    #de_out.shape = (1, batch_size, hidden_size)\n",
        "    #hidden.shape = (2, batch_size, hidden_size)\n",
        "    #cell.shape   = (2, batch_size, hidden_size)\n",
        "\n",
        "    de_out = self.fc_decoder(de_out)\n",
        "    #de_out.shape = (1, batch_size, vocab_size)\n",
        "    de_out = de_out.squeeze(0) \n",
        "    #de_out.shape = (batch_size, vocab_size)\n",
        "\n",
        "    return de_out, hidden, cell"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDSqAywILbsO"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "  def __init__(self, encoder, decoder):\n",
        "    super().__init__()\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "  def forward(self, source, target, tfr = 0.5):\n",
        "    batch_size = target.shape[1]\n",
        "    target_len = target.shape[0]\n",
        "    hj, s_i_minOne, cell = self.encoder(source)\n",
        "    #hj.shape         = (seq_length, batch_size, hidden_size)\n",
        "    #s_i_minOne.shape = (num_layers, batch_size, hidden_size)\n",
        "    #cell.shape       = (num_layers, batch_size, hidden_size)\n",
        "\n",
        "    vocab_size = len(enField.vocab)\n",
        "\n",
        "    outputs = torch.zeros(target_len, batch_size, vocab_size).to(device)\n",
        "\n",
        "    # <SOS>\n",
        "    inp = target[0]\n",
        "    # inp.shape = (32,)\n",
        "\n",
        "    for t in range(1, target_len):\n",
        "      output, s_i_minOne, cell = self.decoder(hj, s_i_minOne, cell, inp)\n",
        "      #output.shape = (batch_size, vocab_size)\n",
        "      #hidden.shape = (num_layer, batch_size, hidden_size)\n",
        "      #cell.shape   = (num_layer, batch_size, hidden_size)\n",
        "      \n",
        "      outputs[t] = output\n",
        "\n",
        "      best_guess = output.argmax(1)\n",
        "      inp = target[t] if random.random() > tfr else best_guess\n",
        "    \n",
        "    return outputs\n",
        "      "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIPaJt4rrLCQ"
      },
      "source": [
        "encoder = Encoder(encoder_input_size, embedding_dim, hidden_size, num_layers, dropout).to(device)\n",
        "decoder = Decoder(decoder_input_size, embedding_dim, hidden_size, num_layers, dropout).to(device)\n",
        "seq2seq = Seq2Seq(encoder, decoder).to(device)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuHvPbtkQdn5"
      },
      "source": [
        "pad_idx = enField.vocab.stoi['<pad>']\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = pad_idx)\n",
        "optimizer = optim.Adam(seq2seq.parameters(), lr = 0.001)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-jX0zPxtSCd"
      },
      "source": [
        "plot_ = {'avg_loss' : [], 'epoch' : []}"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAa3fPFb2G_1"
      },
      "source": [
        "load_model = False\n",
        "\n",
        "if load_model:\n",
        "  model_name    = 'AlvinSeq2Seq_attn'\n",
        "  current_epoch = 0\n",
        "  path = f\"{main_path}/Checkpoint/|Model_{model_name}|Epoch_{current_epoch}.pth.tar\"\n",
        "  load_checkpoint(torch.load(path), seq2seq, optimizer)\n",
        "else:\n",
        "  model_name = 'Seq2SeqAttn'\n",
        "  current_epoch = 0"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8vGPPs7EPUv"
      },
      "source": [
        "import datetime\n",
        "import pytz\n",
        "\n",
        "time_zone = pytz.timezone('Asia/Jakarta')\n",
        "\n",
        "def delta_time(start_time, stop_time):\n",
        "  delta_time = stop_time - start_time\n",
        "  minute, second = divmod(delta_time.total_seconds(), 60)  \n",
        "  hour, minute   = divmod(minute, 60)  \n",
        "\n",
        "  return int(hour), int(minute), int(second)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmeccsWpCCmJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ecb7899-acc6-4717-ca82-44eeb6f1062b"
      },
      "source": [
        "start_time = datetime.datetime.now(time_zone)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  epoch_loss     = 0\n",
        "  iteration_loss = [] \n",
        "\n",
        "  for batch_idx, batch in enumerate(train_iterator):\n",
        "    source = batch.src.to(device)\n",
        "    target = batch.trg.to(device)\n",
        "\n",
        "    outputs = seq2seq(source, target)\n",
        "    outputs = outputs[1:].reshape(-1, outputs.shape[2])\n",
        "    ground_Truth = target[1:].reshape(-1)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss = criterion(outputs, ground_Truth)\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm(seq2seq.parameters(), max_norm = 1)\n",
        "    optimizer.step()\n",
        "    loss_val = loss.item()\n",
        "    iteration_loss.append(loss_val)\n",
        "\n",
        "    epoch_loss += loss_val\n",
        "\n",
        "    # Average loss for the last 100 iteration \n",
        "    if not batch_idx % 100 and batch_idx != 0:\n",
        "      print(f\"EPOCH : {epoch}/{num_epochs - 1} || Batch Iteration : {batch_idx}/{len(train_iterator)} || Avg_Loss from {batch_idx - 100} to {batch_idx} : {sum(iteration_loss[-100:])/100}\") \n",
        "  \n",
        "  \n",
        "  avg_loss = epoch_loss/len(train_iterator)\n",
        "  plot_['avg_loss'].append(avg_loss)\n",
        "  plot_['epoch'].append(epoch)\n",
        "\n",
        "  # Save Current Checkpoint and Plot\n",
        "  checkpoint = {'state_dict' : seq2seq.state_dict(), 'optimizer': optimizer.state_dict()}\n",
        "  save_checkpoint(checkpoint, \n",
        "                  filename=f\"{main_path}Checkpoint/|Model_{model_name}|Epoch_{current_epoch}.pth.tar\")  \n",
        "  \n",
        "  np.save(f\"{main_path}plot/AvgLoss_Model_{model_name}|Epoch_{current_epoch}\", \\\n",
        "                              np.array(plot_['avg_loss']))  \n",
        "  np.save(f\"{main_path}plot/Epoch_Model_{model_name}|Epoch_{current_epoch}\", \\\n",
        "                              np.array(plot_['epoch']))  \n",
        "\n",
        "  # Remove Previous Checkpoint and Plot\n",
        "  if epoch > 0:\n",
        "    os.remove(f\"{main_path}Checkpoint/|Model_{model_name}|Epoch_{current_epoch - 1}.pth.tar\")    \n",
        "    os.remove(f\"{main_path}plot/AvgLoss_Model_{model_name}|Epoch_{current_epoch - 1}.npy\")\n",
        "    os.remove(f\"{main_path}plot/Epoch_Model_{model_name}|Epoch_{current_epoch - 1}.npy\")\n",
        "\n",
        "  if epoch == num_epochs - 1:\n",
        "    stop_time = datetime.datetime.now(time_zone)\n",
        "    hour, minute, second = delta_time(start_time, stop_time)\n",
        "\n",
        "    print(\"\")\n",
        "    print(f\" **************  TRAINING DONE {num_epochs} EPOCHS  ************\")\n",
        "    print(f\" **********  {hour} Hours, {minute} Minutes, {second} Seconds  ********\")        \n",
        "    print(\" ====================================================\")  \n",
        "    print(f\"|              Average Loss : {avg_loss}     |\")   \n",
        "    print(\" ====================================================\")  \n",
        "\n",
        "  else:\n",
        "    print(f\" ************** EPOCH - {epoch}/{num_epochs - 1} **************\")\n",
        "    print(f\"|       Average Loss : {avg_loss}           |\")   \n",
        "    print(\" ********************************************\")         \n",
        "    print(\"\")\n",
        "\n",
        "  current_epoch += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH : 0/9 || Batch Iteration : 100/907 || Avg_Loss from 0 to 100 : 5.285993185043335\n",
            "EPOCH : 0/9 || Batch Iteration : 200/907 || Avg_Loss from 100 to 200 : 4.8126041173934935\n",
            "EPOCH : 0/9 || Batch Iteration : 300/907 || Avg_Loss from 200 to 300 : 4.6542918229103085\n",
            "EPOCH : 0/9 || Batch Iteration : 400/907 || Avg_Loss from 300 to 400 : 4.5080348944664\n",
            "EPOCH : 0/9 || Batch Iteration : 500/907 || Avg_Loss from 400 to 500 : 4.455879228115082\n",
            "EPOCH : 0/9 || Batch Iteration : 600/907 || Avg_Loss from 500 to 600 : 4.315963315963745\n",
            "EPOCH : 0/9 || Batch Iteration : 700/907 || Avg_Loss from 600 to 700 : 4.27121946811676\n",
            "EPOCH : 0/9 || Batch Iteration : 800/907 || Avg_Loss from 700 to 800 : 4.2329288721084595\n",
            "EPOCH : 0/9 || Batch Iteration : 900/907 || Avg_Loss from 800 to 900 : 4.177702927589417\n",
            "=> Saving checkpoint\n",
            " ************** EPOCH - 0/9 **************\n",
            "|       Average Loss : 4.525826414469979           |\n",
            " ********************************************\n",
            "\n",
            "EPOCH : 1/9 || Batch Iteration : 100/907 || Avg_Loss from 0 to 100 : 4.095826661586761\n",
            "EPOCH : 1/9 || Batch Iteration : 200/907 || Avg_Loss from 100 to 200 : 4.039930789470673\n",
            "EPOCH : 1/9 || Batch Iteration : 300/907 || Avg_Loss from 200 to 300 : 3.9993330597877503\n",
            "EPOCH : 1/9 || Batch Iteration : 400/907 || Avg_Loss from 300 to 400 : 3.9406629943847657\n",
            "EPOCH : 1/9 || Batch Iteration : 500/907 || Avg_Loss from 400 to 500 : 3.9583818125724792\n",
            "EPOCH : 1/9 || Batch Iteration : 600/907 || Avg_Loss from 500 to 600 : 3.9144188523292542\n",
            "EPOCH : 1/9 || Batch Iteration : 700/907 || Avg_Loss from 600 to 700 : 3.9352210688591005\n",
            "EPOCH : 1/9 || Batch Iteration : 800/907 || Avg_Loss from 700 to 800 : 3.831776168346405\n",
            "EPOCH : 1/9 || Batch Iteration : 900/907 || Avg_Loss from 800 to 900 : 3.829537127017975\n",
            "=> Saving checkpoint\n",
            " ************** EPOCH - 1/9 **************\n",
            "|       Average Loss : 3.950544081554392           |\n",
            " ********************************************\n",
            "\n",
            "EPOCH : 2/9 || Batch Iteration : 100/907 || Avg_Loss from 0 to 100 : 3.7335328459739685\n",
            "EPOCH : 2/9 || Batch Iteration : 200/907 || Avg_Loss from 100 to 200 : 3.7379463791847227\n",
            "EPOCH : 2/9 || Batch Iteration : 300/907 || Avg_Loss from 200 to 300 : 3.6928513860702514\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtwP934-qORH"
      },
      "source": [
        "#source  \n",
        "plt.plot(plot_['epoch'], plot_['avg_loss'])\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('avg_loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9jv0HdRE-ho"
      },
      "source": [
        "plot_['avg_loss'] = np.save(Avgloss_plot_path, np.array(plot_['avg_loss']))\n",
        "plot_['epoch']    = np.save(Epoch_plot_path, np.array(plot_['epoch']))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}